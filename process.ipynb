{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9148bca1-6d7b-4757-a5c4-eb7b465e57ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u8k: 100%|█████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 81.48it/s]\n",
      "esc: 100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 132368.80it/s]\n",
      "zen: 100%|█████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<?, ?it/s]\n",
      "Global Bounds: 100%|███████████████████████████████████████████████████████████████████| 24/24 [09:03<00:00, 22.66s/it]\n",
      "Processing Samples: 100%|██████████████████████████████████████████████████████████████| 24/24 [14:07<00:00, 35.32s/it]\n",
      "Saving Files: 100%|█████████████████████████████████████████████████████████████| 53385/53385 [02:16<00:00, 391.06it/s]\n",
      "Saving Files: 100%|███████████████████████████████████████████████████████████████| 6673/6673 [00:14<00:00, 460.98it/s]\n",
      "Saving Files: 100%|███████████████████████████████████████████████████████████████| 6674/6674 [00:18<00:00, 351.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.signal import butter, sosfilt, resample_poly, stft\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "# ————————————\n",
    "# Your generalized processing function:\n",
    "def process_audio_general(\n",
    "    path,\n",
    "    target_rates=[1000, 2000, 4000, 8000, 16000, 22000],\n",
    "    high_freq_threshold=11000,\n",
    "    significance_threshold=1e-5\n",
    "):\n",
    "    data, fs = sf.read(path)\n",
    "    if data.ndim > 1:\n",
    "        data = data[:, 0]\n",
    "    chunk_size = fs\n",
    "    n_chunks = len(data) // chunk_size\n",
    "    raw_resampled   = {sr: [] for sr in target_rates}\n",
    "    filtered_resampled = {sr: [] for sr in target_rates}\n",
    "    power = []\n",
    "    rat = []\n",
    "    for i in range(n_chunks):\n",
    "        chunk = data[i*chunk_size:(i+1)*chunk_size]\n",
    "        # power spectral density\n",
    "        psd = np.abs(np.fft.rfft(chunk))**2\n",
    "        freqs = np.fft.rfftfreq(len(chunk), d=1/fs)\n",
    "        total_power = psd.sum()\n",
    "        mean_square_power = psd.sum() / (len(chunk)**2)\n",
    "        # print(\"MSP\", mean_square_power)\n",
    "        if mean_square_power <= significance_threshold:\n",
    "            continue\n",
    "        high_power  = psd[freqs > high_freq_threshold].sum() / (len(chunk)**2)\n",
    "        if high_power / mean_square_power < significance_threshold:\n",
    "            continue\n",
    "        # print(\"HTR\", high_power / mean_square_power)\n",
    "        for sr in target_rates:\n",
    "            # raw resample → “unfiltered”\n",
    "            raw = resample_poly(chunk, sr, fs)\n",
    "            raw_resampled[sr].append(raw)\n",
    "\n",
    "            # filter @ Nyquist(sr), then resample → “filtered”\n",
    "            cutoff = sr / 2\n",
    "            sos = butter(6, cutoff, fs=fs, btype='low', output='sos')\n",
    "            filtered = sosfilt(sos, chunk)\n",
    "            filt_rs = resample_poly(filtered, sr, fs)\n",
    "            filtered_resampled[sr].append(filt_rs)\n",
    "\n",
    "    return raw_resampled, filtered_resampled, fs\n",
    "\n",
    "# ————————————\n",
    "# STFT helper (fixed n_fft & 50% overlap):\n",
    "def generate_stft(chunk, fs, n_fft=512):\n",
    "    f, t, Zxx = stft(chunk, fs=fs, nperseg=n_fft, noverlap=n_fft//2)\n",
    "    return np.abs(Zxx)\n",
    "\n",
    "# ————————————\n",
    "# 1) Gather all files + class IDs\n",
    "def collect_file_list():\n",
    "    files = [[], [], []]\n",
    "    # UrbanSound8K\n",
    "    base1 = r\"D:\\Aliasing3\\UrbanSound8K\\audio\"\n",
    "    for fold in tqdm(range(1, 11), desc=\"u8k\"):\n",
    "        for path in glob.glob(os.path.join(base1, f\"fold{fold}\", \"*.wav\")):\n",
    "            cls = os.path.basename(path).split('-')[1]  # e.g. “7061-6-0-0.wav” → class “6”\n",
    "            files[0].append({'path': path, 'class': cls})\n",
    "    # ESC‑50\n",
    "    base2 = r\"D:\\Aliasing3\\ESC-50-master\\audio\"\n",
    "    for path in tqdm(glob.glob(os.path.join(base2, \"*.wav\")), desc=\"esc\"):\n",
    "        name = os.path.basename(path).rsplit('.', 1)[0].split('-')\n",
    "        cls = name[-1]  # “1-137-A-32.wav” → class “32”\n",
    "        files[1].append({'path': path, 'class': cls})\n",
    "    # Zenodo\n",
    "    base3 = r\"D:\\Aliasing3\\Zenodo\\audio_train\"\n",
    "    for path in tqdm(glob.glob(os.path.join(base3, \"*.flac\")), desc=\"zen\"):\n",
    "        files[2].append({'path': path, 'class': '0'})  # no class → “0”\n",
    "    return [files[0], files[1], files[2]]\n",
    "\n",
    "# ————————————\n",
    "# 2) First pass → global min/max of every STFT bin\n",
    "def find_global_bounds(file_list):\n",
    "    lo, hi = np.inf, -np.inf\n",
    "    for entry in tqdm(file_list, desc=\"Global Bounds\"):\n",
    "        raw, filt, fs = process_audio_general(entry['path'])\n",
    "        for d in (raw, filt):\n",
    "            for sr, chunks in d.items():\n",
    "                for chunk in chunks:\n",
    "                    mag = generate_stft(chunk, fs)\n",
    "                    lo = min(lo, mag.min())\n",
    "                    hi = max(hi, mag.max())\n",
    "    return lo, hi\n",
    "\n",
    "# ————————————\n",
    "# 3) Second pass → normalize & save .npy, then split\n",
    "def build_and_save_dataset(file_list, lo, hi, out_root,\n",
    "                           train_frac=0.8, val_frac=0.1, seed=42):\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "    all_samples = []\n",
    "\n",
    "    # --- collect with 'sr' in metadata ---\n",
    "    for entry in tqdm(file_list, desc=\"Processing Samples\"):\n",
    "        raw, filt, fs = process_audio_general(entry['path'])\n",
    "        for label, d in [('unfiltered', raw), ('filtered', filt)]:\n",
    "            for sr, chunks in d.items():\n",
    "                for chunk in chunks:\n",
    "                    mag = generate_stft(chunk, sr)   # use sr as fs here!\n",
    "                    norm = (mag - lo) / (hi - lo)\n",
    "                    all_samples.append({\n",
    "                        'array': norm.astype(np.float32),\n",
    "                        'label': label,\n",
    "                        'class': entry['class'],\n",
    "                        'sr': sr\n",
    "                    })\n",
    "\n",
    "    # shuffle & split\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_samples)\n",
    "    N = len(all_samples)\n",
    "    n_train = int(train_frac * N)\n",
    "    n_val   = int(val_frac  * N)\n",
    "\n",
    "    splits = {\n",
    "        'train':      all_samples[            :n_train],\n",
    "        'validation': all_samples[n_train    :n_train+n_val],\n",
    "        'test':       all_samples[n_train+n_val:]\n",
    "    }\n",
    "\n",
    "    # save out\n",
    "    counters = {}\n",
    "    for sp, samples in splits.items():\n",
    "        for s in tqdm(samples, desc=\"Saving Files\"):\n",
    "            sr = s['sr']\n",
    "            lbl = s['label']\n",
    "            # initialize counter for this combination\n",
    "            counters.setdefault((sr, sp, lbl), 0)\n",
    "            counters[(sr, sp, lbl)] += 1\n",
    "\n",
    "            idx = counters[(sr, sp, lbl)]\n",
    "            fname = f\"{idx}-{s['class']}.npy\"\n",
    "\n",
    "            # new path: out_root/{sr}/{split}/{label}\n",
    "            save_dir = os.path.join(out_root, str(sr), sp, lbl)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            full_path = os.path.join(save_dir, fname)\n",
    "            np.save(full_path, s['array'])\n",
    "\n",
    "\n",
    "def create_mfcc_dataset(\n",
    "    file_list,\n",
    "    out_root,\n",
    "    target_rates=[1000, 2000, 4000, 8000, 16000, 22000],\n",
    "    n_mfcc=20,\n",
    "    train_frac=0.8,\n",
    "    val_frac=0.1,\n",
    "    seed=42,\n",
    "    high_freq_threshold=11000,\n",
    "    significance_threshold=1e-5\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a MFCC-based dataset from processed chunks, mirroring the STFT pipeline:\n",
    "      - Uses process_audio_general to generate 'unfiltered' & 'filtered' chunks at each sr.\n",
    "      - Computes MFCCs (n_mfcc coefficients) on each chunk (resampled at its sr).\n",
    "      - Flattens each MFCC matrix to a 1D feature vector.\n",
    "      - Shuffles and splits into train/validation/test (80/10/10 by default).\n",
    "      - Normalizes features with z-score (mean/std) computed on TRAIN only.\n",
    "      - Saves each flattened, normalized feature vector as .npy under:\n",
    "\n",
    "        out_root/{sr}/{split}/{filtered|unfiltered}/<idx>-<class>.npy\n",
    "\n",
    "      - Also saves normalization stats to out_root/mfcc_norm_stats.npz\n",
    "    \"\"\"\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "    samples = []\n",
    "\n",
    "    # 1) Gather all MFCC features\n",
    "    for entry in tqdm(file_list, desc=\"Generating MFCC features\"):\n",
    "        raw_dict, filt_dict, _ = process_audio_general(\n",
    "            entry['path'],\n",
    "            target_rates=target_rates,\n",
    "            high_freq_threshold=high_freq_threshold,\n",
    "            significance_threshold=significance_threshold\n",
    "        )\n",
    "        for label, d in [('unfiltered', raw_dict), ('filtered', filt_dict)]:\n",
    "            for sr, chunks in d.items():\n",
    "                for chunk in chunks:\n",
    "                    # compute MFCC on resampled chunk\n",
    "                    mfcc = librosa.feature.mfcc(\n",
    "                        y=chunk,\n",
    "                        sr=sr,\n",
    "                        n_mfcc=n_mfcc,\n",
    "                        n_fft=sr//2,\n",
    "                        hop_length=sr//4\n",
    "                    )\n",
    "                    feat = mfcc.flatten()\n",
    "                    samples.append({\n",
    "                        'feat': feat.astype(np.float32),\n",
    "                        'label': label,\n",
    "                        'class': entry['class'],\n",
    "                        'sr': sr\n",
    "                    })\n",
    "\n",
    "    # 2) Shuffle & split\n",
    "    random.seed(seed)\n",
    "    random.shuffle(samples)\n",
    "    N = len(samples)\n",
    "    n_train = int(train_frac * N)\n",
    "    n_val   = int(val_frac   * N)\n",
    "\n",
    "    splits = {\n",
    "        'train':      samples[:n_train],\n",
    "        'validation': samples[n_train:n_train+n_val],\n",
    "        'test':       samples[n_train+n_val:]\n",
    "    }\n",
    "\n",
    "    # 3) Compute normalization on TRAIN only\n",
    "    feats_train = np.vstack([s['feat'] for s in splits['train']])\n",
    "    mean = feats_train.mean(axis=0)\n",
    "    std  = feats_train.std(axis=0) + 1e-8\n",
    "    np.savez(os.path.join(out_root, 'mfcc_norm_stats.npz'), mean=mean, std=std)\n",
    "\n",
    "    # 4) Save normalized features per split/sr/label\n",
    "    counters = {}\n",
    "    for split_name, split_samples in splits.items():\n",
    "        for s in tqdm(split_samples, desc=f\"Saving {split_name}\"):\n",
    "            sr    = s['sr']\n",
    "            label = s['label']\n",
    "            cls   = s['class']\n",
    "            key = (sr, split_name, label)\n",
    "            counters.setdefault(key, 0)\n",
    "            counters[key] += 1\n",
    "            idx = counters[key]\n",
    "\n",
    "            # normalize\n",
    "            norm_feat = (s['feat'] - mean) / std\n",
    "\n",
    "            # path: out_root/sr/split/label\n",
    "            save_dir = os.path.join(out_root, str(sr), split_name, label)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            fname = f\"{idx}-{cls}.npy\"\n",
    "            np.save(os.path.join(save_dir, fname), norm_feat)\n",
    "\n",
    "    print(f\"MFCC dataset saved under {out_root}\")\n",
    "# ————————————\n",
    "if __name__ == \"__main__\":\n",
    "    file_list = collect_file_list()\n",
    "    # lo1, hi1     = find_global_bounds(file_list[0])\n",
    "    # lo2, hi2     = find_global_bounds(file_list[1])\n",
    "    lo3, hi3     = find_global_bounds(file_list[2])\n",
    "    # build_and_save_dataset(\n",
    "    #     file_list[0],\n",
    "    #     lo1, hi1,\n",
    "    #     out_root=r\"D:\\Aliasing3\\Processed_Files\\DS_U8K\"\n",
    "    # )\n",
    "    # build_and_save_dataset(\n",
    "    #     file_list[1],\n",
    "    #     lo2, hi2,\n",
    "    #     out_root=r\"D:\\Aliasing3\\Processed_Files\\DS_ESC\"\n",
    "    # )\n",
    "    build_and_save_dataset(\n",
    "        file_list[2],\n",
    "        lo3, hi3,\n",
    "        out_root=r\"D:\\Aliasing3\\Processed_Files\\DS_ZEN\"\n",
    "    )\n",
    "    # lists = collect_file_list()\n",
    "    # out_roots = [\n",
    "    #     # r\"D:\\Aliasing3\\Processed_Files\\DS_U8K_MFCC\",\n",
    "    #     # r\"D:\\Aliasing3\\Processed_Files\\DS_ESC_MFCC\",\n",
    "    #     r\"D:\\Aliasing3\\Processed_Files\\DS_ZEN_MFCC\",\n",
    "    # ]\n",
    "    # for flist, root in zip(lists, out_roots):\n",
    "    #     create_mfcc_dataset(flist, root)\n",
    "    # print(\"Done! 🎉  Your train/validation/test splits are in Processed_Files.\")\n",
    "\n",
    "# **Key points:**\n",
    "# - **Two‑pass normalization** ensures every `.npy` STFT uses the same min/max scale.\n",
    "# - **80/10/10 split**, shuffled with a fixed seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9e3ee7-1465-4bb1-bf45-72f50a422737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_U8K | 1000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 1000Hz: 100%|█████████████████████████████████████████████| 5056/5056 [00:56<00:00, 89.39it/s]\n",
      "Loading train filtered 1000Hz: 100%|███████████████████████████████████████████████| 5040/5040 [01:00<00:00, 83.75it/s]\n",
      "Loading validation unfiltered 1000Hz: 100%|██████████████████████████████████████████| 596/596 [00:06<00:00, 89.42it/s]\n",
      "Loading validation filtered 1000Hz: 100%|███████████████████████████████████████████| 618/618 [00:05<00:00, 103.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.6737, F1 (macro): 0.6737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.67      0.67      0.67       596\n",
      "    filtered       0.67      0.67      0.67       596\n",
      "\n",
      "    accuracy                           0.67      1192\n",
      "   macro avg       0.67      0.67      0.67      1192\n",
      "weighted avg       0.67      0.67      0.67      1192\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\xgboost_1000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.5285, F1 (macro): 0.5285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.53      0.53      0.53       596\n",
      "    filtered       0.53      0.53      0.53       596\n",
      "\n",
      "    accuracy                           0.53      1192\n",
      "   macro avg       0.53      0.53      0.53      1192\n",
      "weighted avg       0.53      0.53      0.53      1192\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\random_forest_boost_1000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.7005, F1 (macro): 0.7005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.70      0.70      0.70       596\n",
      "    filtered       0.70      0.70      0.70       596\n",
      "\n",
      "    accuracy                           0.70      1192\n",
      "   macro avg       0.70      0.70      0.70      1192\n",
      "weighted avg       0.70      0.70      0.70      1192\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\adaboost_dt_1000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_U8K | 2000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 2000Hz: 100%|█████████████████████████████████████████████| 5024/5024 [01:05<00:00, 77.23it/s]\n",
      "Loading train filtered 2000Hz: 100%|███████████████████████████████████████████████| 5025/5025 [01:10<00:00, 71.52it/s]\n",
      "Loading validation unfiltered 2000Hz: 100%|██████████████████████████████████████████| 637/637 [00:07<00:00, 83.04it/s]\n",
      "Loading validation filtered 2000Hz: 100%|████████████████████████████████████████████| 632/632 [00:08<00:00, 71.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7002, F1 (macro): 0.7001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.69      0.72      0.70       632\n",
      "    filtered       0.71      0.69      0.70       632\n",
      "\n",
      "    accuracy                           0.70      1264\n",
      "   macro avg       0.70      0.70      0.70      1264\n",
      "weighted avg       0.70      0.70      0.70      1264\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\xgboost_2000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.5672, F1 (macro): 0.5672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.57      0.58      0.57       632\n",
      "    filtered       0.57      0.56      0.56       632\n",
      "\n",
      "    accuracy                           0.57      1264\n",
      "   macro avg       0.57      0.57      0.57      1264\n",
      "weighted avg       0.57      0.57      0.57      1264\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\random_forest_boost_2000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.7207, F1 (macro): 0.7207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.72      0.72      0.72       632\n",
      "    filtered       0.72      0.72      0.72       632\n",
      "\n",
      "    accuracy                           0.72      1264\n",
      "   macro avg       0.72      0.72      0.72      1264\n",
      "weighted avg       0.72      0.72      0.72      1264\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\adaboost_dt_2000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_U8K | 4000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 4000Hz: 100%|█████████████████████████████████████████████| 5029/5029 [01:10<00:00, 70.98it/s]\n",
      "Loading train filtered 4000Hz: 100%|███████████████████████████████████████████████| 5052/5052 [01:14<00:00, 67.76it/s]\n",
      "Loading validation unfiltered 4000Hz: 100%|██████████████████████████████████████████| 632/632 [00:09<00:00, 67.35it/s]\n",
      "Loading validation filtered 4000Hz: 100%|████████████████████████████████████████████| 626/626 [00:08<00:00, 71.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7244, F1 (macro): 0.7244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.73      0.71      0.72       626\n",
      "    filtered       0.72      0.74      0.73       626\n",
      "\n",
      "    accuracy                           0.72      1252\n",
      "   macro avg       0.72      0.72      0.72      1252\n",
      "weighted avg       0.72      0.72      0.72      1252\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\xgboost_4000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.5535, F1 (macro): 0.5535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.55      0.54      0.55       626\n",
      "    filtered       0.55      0.56      0.56       626\n",
      "\n",
      "    accuracy                           0.55      1252\n",
      "   macro avg       0.55      0.55      0.55      1252\n",
      "weighted avg       0.55      0.55      0.55      1252\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\random_forest_boost_4000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.7085, F1 (macro): 0.7085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.71      0.72      0.71       626\n",
      "    filtered       0.71      0.70      0.71       626\n",
      "\n",
      "    accuracy                           0.71      1252\n",
      "   macro avg       0.71      0.71      0.71      1252\n",
      "weighted avg       0.71      0.71      0.71      1252\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\adaboost_dt_4000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_U8K | 8000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 8000Hz: 100%|█████████████████████████████████████████████| 4975/4975 [01:37<00:00, 50.92it/s]\n",
      "Loading train filtered 8000Hz: 100%|███████████████████████████████████████████████| 5026/5026 [01:39<00:00, 50.51it/s]\n",
      "Loading validation unfiltered 8000Hz: 100%|██████████████████████████████████████████| 670/670 [00:13<00:00, 51.27it/s]\n",
      "Loading validation filtered 8000Hz: 100%|████████████████████████████████████████████| 617/617 [00:11<00:00, 52.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7472, F1 (macro): 0.7469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.73      0.78      0.75       617\n",
      "    filtered       0.76      0.72      0.74       617\n",
      "\n",
      "    accuracy                           0.75      1234\n",
      "   macro avg       0.75      0.75      0.75      1234\n",
      "weighted avg       0.75      0.75      0.75      1234\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\xgboost_8000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.5446, F1 (macro): 0.5446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.54      0.55      0.55       617\n",
      "    filtered       0.55      0.54      0.54       617\n",
      "\n",
      "    accuracy                           0.54      1234\n",
      "   macro avg       0.54      0.54      0.54      1234\n",
      "weighted avg       0.54      0.54      0.54      1234\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\random_forest_boost_8000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.7018, F1 (macro): 0.7017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.71      0.68      0.70       617\n",
      "    filtered       0.69      0.72      0.71       617\n",
      "\n",
      "    accuracy                           0.70      1234\n",
      "   macro avg       0.70      0.70      0.70      1234\n",
      "weighted avg       0.70      0.70      0.70      1234\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\adaboost_dt_8000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_U8K | 16000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 16000Hz: 100%|████████████████████████████████████████████| 5030/5030 [01:34<00:00, 53.11it/s]\n",
      "Loading train filtered 16000Hz: 100%|██████████████████████████████████████████████| 5077/5077 [01:33<00:00, 54.19it/s]\n",
      "Loading validation unfiltered 16000Hz: 100%|█████████████████████████████████████████| 657/657 [00:11<00:00, 56.95it/s]\n",
      "Loading validation filtered 16000Hz: 100%|███████████████████████████████████████████| 609/609 [00:11<00:00, 53.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7176, F1 (macro): 0.7175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.73      0.70      0.71       609\n",
      "    filtered       0.71      0.74      0.72       609\n",
      "\n",
      "    accuracy                           0.72      1218\n",
      "   macro avg       0.72      0.72      0.72      1218\n",
      "weighted avg       0.72      0.72      0.72      1218\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\xgboost_16000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.5493, F1 (macro): 0.5493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.55      0.55      0.55       609\n",
      "    filtered       0.55      0.55      0.55       609\n",
      "\n",
      "    accuracy                           0.55      1218\n",
      "   macro avg       0.55      0.55      0.55      1218\n",
      "weighted avg       0.55      0.55      0.55      1218\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\random_forest_boost_16000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.7053, F1 (macro): 0.7053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.70      0.71      0.71       609\n",
      "    filtered       0.71      0.70      0.70       609\n",
      "\n",
      "    accuracy                           0.71      1218\n",
      "   macro avg       0.71      0.71      0.71      1218\n",
      "weighted avg       0.71      0.71      0.71      1218\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\adaboost_dt_16000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_U8K | 22000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 22000Hz: 100%|████████████████████████████████████████████| 5067/5067 [01:39<00:00, 50.99it/s]\n",
      "Loading train filtered 22000Hz: 100%|██████████████████████████████████████████████| 4973/4973 [01:41<00:00, 49.15it/s]\n",
      "Loading validation unfiltered 22000Hz: 100%|█████████████████████████████████████████| 577/577 [00:11<00:00, 49.38it/s]\n",
      "Loading validation filtered 22000Hz: 100%|███████████████████████████████████████████| 675/675 [00:13<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7184, F1 (macro): 0.7184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.72      0.72      0.72       577\n",
      "    filtered       0.72      0.71      0.72       577\n",
      "\n",
      "    accuracy                           0.72      1154\n",
      "   macro avg       0.72      0.72      0.72      1154\n",
      "weighted avg       0.72      0.72      0.72      1154\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\xgboost_22000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.5433, F1 (macro): 0.5431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.54      0.56      0.55       577\n",
      "    filtered       0.55      0.52      0.53       577\n",
      "\n",
      "    accuracy                           0.54      1154\n",
      "   macro avg       0.54      0.54      0.54      1154\n",
      "weighted avg       0.54      0.54      0.54      1154\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\random_forest_boost_22000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.7132, F1 (macro): 0.7132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.71      0.71      0.71       577\n",
      "    filtered       0.71      0.71      0.71       577\n",
      "\n",
      "    accuracy                           0.71      1154\n",
      "   macro avg       0.71      0.71      0.71      1154\n",
      "weighted avg       0.71      0.71      0.71      1154\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_U8K\\models\\adaboost_dt_22000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_ZEN | 1000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 1000Hz: 100%|█████████████████████████████████████████████| 4485/4485 [00:59<00:00, 75.50it/s]\n",
      "Loading train filtered 1000Hz: 100%|███████████████████████████████████████████████| 4457/4457 [00:57<00:00, 77.80it/s]\n",
      "Loading validation unfiltered 1000Hz: 100%|██████████████████████████████████████████| 537/537 [00:07<00:00, 74.29it/s]\n",
      "Loading validation filtered 1000Hz: 100%|████████████████████████████████████████████| 555/555 [00:06<00:00, 82.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7011, F1 (macro): 0.7009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.71      0.67      0.69       537\n",
      "    filtered       0.69      0.73      0.71       537\n",
      "\n",
      "    accuracy                           0.70      1074\n",
      "   macro avg       0.70      0.70      0.70      1074\n",
      "weighted avg       0.70      0.70      0.70      1074\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\xgboost_1000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.3752, F1 (macro): 0.3751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.37      0.36      0.37       537\n",
      "    filtered       0.38      0.39      0.38       537\n",
      "\n",
      "    accuracy                           0.38      1074\n",
      "   macro avg       0.38      0.38      0.38      1074\n",
      "weighted avg       0.38      0.38      0.38      1074\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\random_forest_boost_1000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.5466, F1 (macro): 0.5465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.55      0.54      0.54       537\n",
      "    filtered       0.55      0.56      0.55       537\n",
      "\n",
      "    accuracy                           0.55      1074\n",
      "   macro avg       0.55      0.55      0.55      1074\n",
      "weighted avg       0.55      0.55      0.55      1074\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\adaboost_dt_1000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_ZEN | 2000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 2000Hz: 100%|█████████████████████████████████████████████| 4416/4416 [00:58<00:00, 75.94it/s]\n",
      "Loading train filtered 2000Hz: 100%|███████████████████████████████████████████████| 4437/4437 [00:59<00:00, 74.75it/s]\n",
      "Loading validation unfiltered 2000Hz: 100%|██████████████████████████████████████████| 546/546 [00:07<00:00, 75.38it/s]\n",
      "Loading validation filtered 2000Hz: 100%|████████████████████████████████████████████| 564/564 [00:07<00:00, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.01, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7033, F1 (macro): 0.7033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.71      0.69      0.70       546\n",
      "    filtered       0.70      0.71      0.71       546\n",
      "\n",
      "    accuracy                           0.70      1092\n",
      "   macro avg       0.70      0.70      0.70      1092\n",
      "weighted avg       0.70      0.70      0.70      1092\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\xgboost_2000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.3645, F1 (macro): 0.3638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.37      0.40      0.38       546\n",
      "    filtered       0.35      0.33      0.34       546\n",
      "\n",
      "    accuracy                           0.36      1092\n",
      "   macro avg       0.36      0.36      0.36      1092\n",
      "weighted avg       0.36      0.36      0.36      1092\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\random_forest_boost_2000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.5385, F1 (macro): 0.5385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.54      0.54      0.54       546\n",
      "    filtered       0.54      0.53      0.54       546\n",
      "\n",
      "    accuracy                           0.54      1092\n",
      "   macro avg       0.54      0.54      0.54      1092\n",
      "weighted avg       0.54      0.54      0.54      1092\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\adaboost_dt_2000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_ZEN | 4000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 4000Hz: 100%|█████████████████████████████████████████████| 4444/4444 [01:08<00:00, 64.61it/s]\n",
      "Loading train filtered 4000Hz: 100%|███████████████████████████████████████████████| 4471/4471 [01:11<00:00, 62.70it/s]\n",
      "Loading validation unfiltered 4000Hz: 100%|██████████████████████████████████████████| 542/542 [00:07<00:00, 68.72it/s]\n",
      "Loading validation filtered 4000Hz: 100%|████████████████████████████████████████████| 538/538 [00:07<00:00, 71.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.8020, F1 (macro): 0.8020\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.79      0.81      0.80       538\n",
      "    filtered       0.81      0.79      0.80       538\n",
      "\n",
      "    accuracy                           0.80      1076\n",
      "   macro avg       0.80      0.80      0.80      1076\n",
      "weighted avg       0.80      0.80      0.80      1076\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\xgboost_4000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.4796, F1 (macro): 0.4792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.48      0.51      0.49       538\n",
      "    filtered       0.48      0.45      0.47       538\n",
      "\n",
      "    accuracy                           0.48      1076\n",
      "   macro avg       0.48      0.48      0.48      1076\n",
      "weighted avg       0.48      0.48      0.48      1076\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\random_forest_boost_4000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.5632, F1 (macro): 0.5632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.56      0.57      0.57       538\n",
      "    filtered       0.56      0.55      0.56       538\n",
      "\n",
      "    accuracy                           0.56      1076\n",
      "   macro avg       0.56      0.56      0.56      1076\n",
      "weighted avg       0.56      0.56      0.56      1076\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\adaboost_dt_4000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_ZEN | 8000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 8000Hz: 100%|█████████████████████████████████████████████| 4437/4437 [01:11<00:00, 61.66it/s]\n",
      "Loading train filtered 8000Hz: 100%|███████████████████████████████████████████████| 4415/4415 [01:12<00:00, 61.02it/s]\n",
      "Loading validation unfiltered 8000Hz: 100%|██████████████████████████████████████████| 563/563 [00:08<00:00, 69.11it/s]\n",
      "Loading validation filtered 8000Hz: 100%|████████████████████████████████████████████| 580/580 [00:08<00:00, 65.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7718, F1 (macro): 0.7718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.77      0.78      0.77       563\n",
      "    filtered       0.77      0.77      0.77       563\n",
      "\n",
      "    accuracy                           0.77      1126\n",
      "   macro avg       0.77      0.77      0.77      1126\n",
      "weighted avg       0.77      0.77      0.77      1126\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\xgboost_8000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.3774, F1 (macro): 0.3774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.38      0.38      0.38       563\n",
      "    filtered       0.38      0.37      0.37       563\n",
      "\n",
      "    accuracy                           0.38      1126\n",
      "   macro avg       0.38      0.38      0.38      1126\n",
      "weighted avg       0.38      0.38      0.38      1126\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\random_forest_boost_8000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.5329, F1 (macro): 0.5327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.53      0.55      0.54       563\n",
      "    filtered       0.53      0.51      0.52       563\n",
      "\n",
      "    accuracy                           0.53      1126\n",
      "   macro avg       0.53      0.53      0.53      1126\n",
      "weighted avg       0.53      0.53      0.53      1126\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\adaboost_dt_8000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_ZEN | 16000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 16000Hz: 100%|████████████████████████████████████████████| 4426/4426 [01:03<00:00, 69.58it/s]\n",
      "Loading train filtered 16000Hz: 100%|██████████████████████████████████████████████| 4439/4439 [01:04<00:00, 68.70it/s]\n",
      "Loading validation unfiltered 16000Hz: 100%|█████████████████████████████████████████| 591/591 [00:07<00:00, 75.66it/s]\n",
      "Loading validation filtered 16000Hz: 100%|███████████████████████████████████████████| 580/580 [00:09<00:00, 61.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.8155, F1 (macro): 0.8155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.81      0.83      0.82       580\n",
      "    filtered       0.83      0.80      0.81       580\n",
      "\n",
      "    accuracy                           0.82      1160\n",
      "   macro avg       0.82      0.82      0.82      1160\n",
      "weighted avg       0.82      0.82      0.82      1160\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\xgboost_16000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.4034, F1 (macro): 0.4034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.40      0.41      0.41       580\n",
      "    filtered       0.40      0.40      0.40       580\n",
      "\n",
      "    accuracy                           0.40      1160\n",
      "   macro avg       0.40      0.40      0.40      1160\n",
      "weighted avg       0.40      0.40      0.40      1160\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\random_forest_boost_16000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.5802, F1 (macro): 0.5801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.58      0.59      0.58       580\n",
      "    filtered       0.58      0.57      0.58       580\n",
      "\n",
      "    accuracy                           0.58      1160\n",
      "   macro avg       0.58      0.58      0.58      1160\n",
      "weighted avg       0.58      0.58      0.58      1160\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\adaboost_dt_16000Hz.pkl\n",
      "\n",
      "=== STFT | Root: D:\\Aliasing3\\Processed_Files\\DS_ZEN | 22000Hz ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train unfiltered 22000Hz: 100%|████████████████████████████████████████████| 4436/4436 [01:07<00:00, 66.05it/s]\n",
      "Loading train filtered 22000Hz: 100%|██████████████████████████████████████████████| 4522/4522 [01:12<00:00, 62.75it/s]\n",
      "Loading validation unfiltered 22000Hz: 100%|█████████████████████████████████████████| 555/555 [00:06<00:00, 80.00it/s]\n",
      "Loading validation filtered 22000Hz: 100%|███████████████████████████████████████████| 522/522 [00:07<00:00, 73.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for XGBoost...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "Training xgboost...\n",
      "Validation Accuracy (xgboost): 0.7749, F1 (macro): 0.7748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.76      0.80      0.78       522\n",
      "    filtered       0.79      0.75      0.77       522\n",
      "\n",
      "    accuracy                           0.77      1044\n",
      "   macro avg       0.78      0.77      0.77      1044\n",
      "weighted avg       0.78      0.77      0.77      1044\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\xgboost_22000Hz.pkl\n",
      "Training random_forest_boost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (random_forest_boost): 0.3190, F1 (macro): 0.3184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.33      0.35      0.34       522\n",
      "    filtered       0.31      0.29      0.30       522\n",
      "\n",
      "    accuracy                           0.32      1044\n",
      "   macro avg       0.32      0.32      0.32      1044\n",
      "weighted avg       0.32      0.32      0.32      1044\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\random_forest_boost_22000Hz.pkl\n",
      "Training adaboost_dt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jta20\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (adaboost_dt): 0.5412, F1 (macro): 0.5412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  unfiltered       0.54      0.54      0.54       522\n",
      "    filtered       0.54      0.54      0.54       522\n",
      "\n",
      "    accuracy                           0.54      1044\n",
      "   macro avg       0.54      0.54      0.54      1044\n",
      "weighted avg       0.54      0.54      0.54      1044\n",
      "\n",
      "Saved model to D:\\Aliasing3\\Processed_Files\\DS_ZEN\\models\\adaboost_dt_22000Hz.pkl\n",
      "Results saved to model_performance_20250726_125159.csv\n",
      "All models trained and results recorded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "SAMPLE_RATES = [1000, 2000, 4000, 8000, 16000, 22000]\n",
    "\n",
    "# Dataset roots for STFT and MFCC pipelines\n",
    "DATASETS = {\n",
    "    'STFT': [\n",
    "        # r\"D:\\Aliasing3\\Processed_Files\\DS_ESC\",\n",
    "        r\"D:\\Aliasing3\\Processed_Files\\DS_U8K\",\n",
    "        r\"D:\\Aliasing3\\Processed_Files\\DS_ZEN\"\n",
    "    ],\n",
    "    # 'MFCC': [\n",
    "    #     r\"D:\\Aliasing3\\Processed_Files\\DS_ESC_MFCC\",\n",
    "    #     r\"D:\\Aliasing3\\Processed_Files\\DS_U8K_MFCC\",\n",
    "    #     r\"D:\\Aliasing3\\Processed_Files\\DS_ZEN_MFCC\"\n",
    "    # ]\n",
    "}\n",
    "\n",
    "# Collect results for CSV output\n",
    "results = []\n",
    "\n",
    "def load_data(root_dir, sr, split):\n",
    "    \"\"\"\n",
    "    Load flattened feature .npy files for a given sample rate and split.\n",
    "    Handles both STFT and MFCC datasets (features already flattened).\n",
    "    Assumes structure: root_dir/{sr}/{split}/{filtered|unfiltered}/*.npy\n",
    "    Returns X (n_samples, n_features), y (n_samples,)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for label, cls in [('unfiltered', 0), ('filtered', 1)]:\n",
    "        folder = os.path.join(root_dir, str(sr), split, label)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        files = glob.glob(os.path.join(folder, '*.npy'))\n",
    "        for fpath in tqdm(files, desc=f\"Loading {split} {label} {sr}Hz\"):\n",
    "            arr = np.load(fpath)\n",
    "            vec = arr.flatten()\n",
    "            X.append(vec)\n",
    "            y.append(cls)\n",
    "    if not X:\n",
    "        return np.empty((0, 0)), np.empty((0,))\n",
    "    return np.vstack(X), np.array(y)\n",
    "\n",
    "\n",
    "def balance_data(X, y, seed=42):\n",
    "    \"\"\"Down-sample majority class to match minority for balanced classes.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    idxs = []\n",
    "    for cls in classes:\n",
    "        cls_idxs = np.where(y == cls)[0]\n",
    "        selected = np.random.choice(cls_idxs, min_count, replace=False)\n",
    "        idxs.extend(selected)\n",
    "    random.shuffle(idxs)\n",
    "    return X[idxs], y[idxs]\n",
    "\n",
    "\n",
    "def train_and_validate_for_rate(root_dir, sr, feature_type):\n",
    "    print(f\"\\n=== {feature_type} | Root: {root_dir} | {sr}Hz ===\")\n",
    "    models_dir = os.path.join(root_dir, 'models')\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    # Check for MFCC normalization stats\n",
    "    norm_path = os.path.join(root_dir, 'mfcc_norm_stats.npz')\n",
    "    have_norm = os.path.isfile(norm_path)\n",
    "    if have_norm:\n",
    "        stats = np.load(norm_path)\n",
    "        mean_vec = stats['mean']\n",
    "        std_vec  = stats['std']\n",
    "\n",
    "    # Load and preprocess training data\n",
    "    X_train, y_train = load_data(root_dir, sr, 'train')\n",
    "    if X_train.size == 0:\n",
    "        print(f\"No training data at {sr}Hz in {root_dir}; skipping.\")\n",
    "        return\n",
    "    if have_norm:\n",
    "        X_train = (X_train - mean_vec) / std_vec\n",
    "    X_train, y_train = balance_data(X_train, y_train)\n",
    "\n",
    "    # Load and preprocess validation data\n",
    "    X_val, y_val = load_data(root_dir, sr, 'validation')\n",
    "    if X_val.size == 0:\n",
    "        print(f\"No validation data at {sr}Hz in {root_dir}; skipping.\")\n",
    "        return\n",
    "    if have_norm:\n",
    "        X_val = (X_val - mean_vec) / std_vec\n",
    "    X_val, y_val = balance_data(X_val, y_val)\n",
    "\n",
    "    # Base classifiers\n",
    "    xgb_base = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_base = AdaBoostClassifier(\n",
    "        estimator=RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "        n_estimators=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    dt_base = AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        n_estimators=5,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Grid search only for XGBoost\n",
    "    print(\"Running grid search for XGBoost...\")\n",
    "    param_grid = {\n",
    "        'max_depth': [5],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        xgb_base,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_xgb = grid.best_estimator_\n",
    "    print(\"Best XGBoost params:\", grid.best_params_)\n",
    "\n",
    "    models = {\n",
    "        'xgboost': best_xgb,\n",
    "        'random_forest_boost': rf_base,\n",
    "        'adaboost_dt': dt_base\n",
    "    }\n",
    "\n",
    "    # Train, evaluate, and save models\n",
    "    for name, clf in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        f1 = f1_score(y_val, preds, average='macro')\n",
    "        print(f\"Validation Accuracy ({name}): {acc:.4f}, F1 (macro): {f1:.4f}\")\n",
    "        print(classification_report(y_val, preds, target_names=['unfiltered', 'filtered']))\n",
    "\n",
    "        # Save model\n",
    "        model_path = os.path.join(models_dir, f\"{name}_{sr}Hz.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(clf, f)\n",
    "        print(f\"Saved model to {model_path}\")\n",
    "\n",
    "        # Record results\n",
    "        results.append({\n",
    "            'feature_type': feature_type,\n",
    "            'dataset_root': root_dir,\n",
    "            'model': name,\n",
    "            'sample_rate': sr,\n",
    "            'f1_score': f1\n",
    "        })\n",
    "\n",
    "\n",
    "def main():\n",
    "    for feature_type, roots in DATASETS.items():\n",
    "        for root_dir in roots:\n",
    "            for sr in SAMPLE_RATES:\n",
    "                train_and_validate_for_rate(root_dir, sr, feature_type)\n",
    "\n",
    "    # Save results to a new CSV with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    csv_file = f\"model_performance_{timestamp}.csv\"\n",
    "    with open(csv_file, 'w', newline='') as cf:\n",
    "        writer = csv.DictWriter(cf, fieldnames=['feature_type', 'dataset_root', 'model', 'sample_rate', 'f1_score'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "    print(f\"Results saved to {csv_file}\")\n",
    "    print(\"All models trained and results recorded.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
